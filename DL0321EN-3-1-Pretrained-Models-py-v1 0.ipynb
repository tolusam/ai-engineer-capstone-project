{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item31'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab. First we will need the library that helps us to import the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import skillsnetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 03:24:13.671679: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-16 03:24:13.675566: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-16 03:24:13.688059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739676253.713215   14997 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739676253.720586   14997 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-16 03:24:13.743166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item32'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to download the data from IBM object storage using **skillsnetwork.prepare** command. skillsnetwork.prepare is a command that's used to download a zip file, unzip it and store it in a specified directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddad04586ea4bde80355416c5653c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading concrete_data_week3.zip:   0%|          | 0/97863179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5827f137e953403083188ca59456baa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to '.'\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/concrete_data_week3.zip\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50** error. So please **DO NOT DO IT**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item33'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Global Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item34'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct ImageDataGenerator Instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    '/mnt/data/concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in this lab, we will be using the full data-set of 30,000 images for training and validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    '/mnt/data/concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item35'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Compile and Fit Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1739676368.657767   14997 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step \n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Functional name=resnet50, built=True>, <Dense name=dense, built=True>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the ResNet50 layers by running the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=input_layer, built=True>,\n",
       " <ZeroPadding2D name=conv1_pad, built=True>,\n",
       " <Conv2D name=conv1_conv, built=True>,\n",
       " <BatchNormalization name=conv1_bn, built=True>,\n",
       " <Activation name=conv1_relu, built=True>,\n",
       " <ZeroPadding2D name=pool1_pad, built=True>,\n",
       " <MaxPooling2D name=pool1_pool, built=True>,\n",
       " <Conv2D name=conv2_block1_1_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block1_1_bn, built=True>,\n",
       " <Activation name=conv2_block1_1_relu, built=True>,\n",
       " <Conv2D name=conv2_block1_2_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block1_2_bn, built=True>,\n",
       " <Activation name=conv2_block1_2_relu, built=True>,\n",
       " <Conv2D name=conv2_block1_0_conv, built=True>,\n",
       " <Conv2D name=conv2_block1_3_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block1_0_bn, built=True>,\n",
       " <BatchNormalization name=conv2_block1_3_bn, built=True>,\n",
       " <Add name=conv2_block1_add, built=True>,\n",
       " <Activation name=conv2_block1_out, built=True>,\n",
       " <Conv2D name=conv2_block2_1_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block2_1_bn, built=True>,\n",
       " <Activation name=conv2_block2_1_relu, built=True>,\n",
       " <Conv2D name=conv2_block2_2_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block2_2_bn, built=True>,\n",
       " <Activation name=conv2_block2_2_relu, built=True>,\n",
       " <Conv2D name=conv2_block2_3_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block2_3_bn, built=True>,\n",
       " <Add name=conv2_block2_add, built=True>,\n",
       " <Activation name=conv2_block2_out, built=True>,\n",
       " <Conv2D name=conv2_block3_1_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block3_1_bn, built=True>,\n",
       " <Activation name=conv2_block3_1_relu, built=True>,\n",
       " <Conv2D name=conv2_block3_2_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block3_2_bn, built=True>,\n",
       " <Activation name=conv2_block3_2_relu, built=True>,\n",
       " <Conv2D name=conv2_block3_3_conv, built=True>,\n",
       " <BatchNormalization name=conv2_block3_3_bn, built=True>,\n",
       " <Add name=conv2_block3_add, built=True>,\n",
       " <Activation name=conv2_block3_out, built=True>,\n",
       " <Conv2D name=conv3_block1_1_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block1_1_bn, built=True>,\n",
       " <Activation name=conv3_block1_1_relu, built=True>,\n",
       " <Conv2D name=conv3_block1_2_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block1_2_bn, built=True>,\n",
       " <Activation name=conv3_block1_2_relu, built=True>,\n",
       " <Conv2D name=conv3_block1_0_conv, built=True>,\n",
       " <Conv2D name=conv3_block1_3_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block1_0_bn, built=True>,\n",
       " <BatchNormalization name=conv3_block1_3_bn, built=True>,\n",
       " <Add name=conv3_block1_add, built=True>,\n",
       " <Activation name=conv3_block1_out, built=True>,\n",
       " <Conv2D name=conv3_block2_1_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block2_1_bn, built=True>,\n",
       " <Activation name=conv3_block2_1_relu, built=True>,\n",
       " <Conv2D name=conv3_block2_2_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block2_2_bn, built=True>,\n",
       " <Activation name=conv3_block2_2_relu, built=True>,\n",
       " <Conv2D name=conv3_block2_3_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block2_3_bn, built=True>,\n",
       " <Add name=conv3_block2_add, built=True>,\n",
       " <Activation name=conv3_block2_out, built=True>,\n",
       " <Conv2D name=conv3_block3_1_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block3_1_bn, built=True>,\n",
       " <Activation name=conv3_block3_1_relu, built=True>,\n",
       " <Conv2D name=conv3_block3_2_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block3_2_bn, built=True>,\n",
       " <Activation name=conv3_block3_2_relu, built=True>,\n",
       " <Conv2D name=conv3_block3_3_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block3_3_bn, built=True>,\n",
       " <Add name=conv3_block3_add, built=True>,\n",
       " <Activation name=conv3_block3_out, built=True>,\n",
       " <Conv2D name=conv3_block4_1_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block4_1_bn, built=True>,\n",
       " <Activation name=conv3_block4_1_relu, built=True>,\n",
       " <Conv2D name=conv3_block4_2_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block4_2_bn, built=True>,\n",
       " <Activation name=conv3_block4_2_relu, built=True>,\n",
       " <Conv2D name=conv3_block4_3_conv, built=True>,\n",
       " <BatchNormalization name=conv3_block4_3_bn, built=True>,\n",
       " <Add name=conv3_block4_add, built=True>,\n",
       " <Activation name=conv3_block4_out, built=True>,\n",
       " <Conv2D name=conv4_block1_1_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block1_1_bn, built=True>,\n",
       " <Activation name=conv4_block1_1_relu, built=True>,\n",
       " <Conv2D name=conv4_block1_2_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block1_2_bn, built=True>,\n",
       " <Activation name=conv4_block1_2_relu, built=True>,\n",
       " <Conv2D name=conv4_block1_0_conv, built=True>,\n",
       " <Conv2D name=conv4_block1_3_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block1_0_bn, built=True>,\n",
       " <BatchNormalization name=conv4_block1_3_bn, built=True>,\n",
       " <Add name=conv4_block1_add, built=True>,\n",
       " <Activation name=conv4_block1_out, built=True>,\n",
       " <Conv2D name=conv4_block2_1_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block2_1_bn, built=True>,\n",
       " <Activation name=conv4_block2_1_relu, built=True>,\n",
       " <Conv2D name=conv4_block2_2_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block2_2_bn, built=True>,\n",
       " <Activation name=conv4_block2_2_relu, built=True>,\n",
       " <Conv2D name=conv4_block2_3_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block2_3_bn, built=True>,\n",
       " <Add name=conv4_block2_add, built=True>,\n",
       " <Activation name=conv4_block2_out, built=True>,\n",
       " <Conv2D name=conv4_block3_1_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block3_1_bn, built=True>,\n",
       " <Activation name=conv4_block3_1_relu, built=True>,\n",
       " <Conv2D name=conv4_block3_2_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block3_2_bn, built=True>,\n",
       " <Activation name=conv4_block3_2_relu, built=True>,\n",
       " <Conv2D name=conv4_block3_3_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block3_3_bn, built=True>,\n",
       " <Add name=conv4_block3_add, built=True>,\n",
       " <Activation name=conv4_block3_out, built=True>,\n",
       " <Conv2D name=conv4_block4_1_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block4_1_bn, built=True>,\n",
       " <Activation name=conv4_block4_1_relu, built=True>,\n",
       " <Conv2D name=conv4_block4_2_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block4_2_bn, built=True>,\n",
       " <Activation name=conv4_block4_2_relu, built=True>,\n",
       " <Conv2D name=conv4_block4_3_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block4_3_bn, built=True>,\n",
       " <Add name=conv4_block4_add, built=True>,\n",
       " <Activation name=conv4_block4_out, built=True>,\n",
       " <Conv2D name=conv4_block5_1_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block5_1_bn, built=True>,\n",
       " <Activation name=conv4_block5_1_relu, built=True>,\n",
       " <Conv2D name=conv4_block5_2_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block5_2_bn, built=True>,\n",
       " <Activation name=conv4_block5_2_relu, built=True>,\n",
       " <Conv2D name=conv4_block5_3_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block5_3_bn, built=True>,\n",
       " <Add name=conv4_block5_add, built=True>,\n",
       " <Activation name=conv4_block5_out, built=True>,\n",
       " <Conv2D name=conv4_block6_1_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block6_1_bn, built=True>,\n",
       " <Activation name=conv4_block6_1_relu, built=True>,\n",
       " <Conv2D name=conv4_block6_2_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block6_2_bn, built=True>,\n",
       " <Activation name=conv4_block6_2_relu, built=True>,\n",
       " <Conv2D name=conv4_block6_3_conv, built=True>,\n",
       " <BatchNormalization name=conv4_block6_3_bn, built=True>,\n",
       " <Add name=conv4_block6_add, built=True>,\n",
       " <Activation name=conv4_block6_out, built=True>,\n",
       " <Conv2D name=conv5_block1_1_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block1_1_bn, built=True>,\n",
       " <Activation name=conv5_block1_1_relu, built=True>,\n",
       " <Conv2D name=conv5_block1_2_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block1_2_bn, built=True>,\n",
       " <Activation name=conv5_block1_2_relu, built=True>,\n",
       " <Conv2D name=conv5_block1_0_conv, built=True>,\n",
       " <Conv2D name=conv5_block1_3_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block1_0_bn, built=True>,\n",
       " <BatchNormalization name=conv5_block1_3_bn, built=True>,\n",
       " <Add name=conv5_block1_add, built=True>,\n",
       " <Activation name=conv5_block1_out, built=True>,\n",
       " <Conv2D name=conv5_block2_1_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block2_1_bn, built=True>,\n",
       " <Activation name=conv5_block2_1_relu, built=True>,\n",
       " <Conv2D name=conv5_block2_2_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block2_2_bn, built=True>,\n",
       " <Activation name=conv5_block2_2_relu, built=True>,\n",
       " <Conv2D name=conv5_block2_3_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block2_3_bn, built=True>,\n",
       " <Add name=conv5_block2_add, built=True>,\n",
       " <Activation name=conv5_block2_out, built=True>,\n",
       " <Conv2D name=conv5_block3_1_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block3_1_bn, built=True>,\n",
       " <Activation name=conv5_block3_1_relu, built=True>,\n",
       " <Conv2D name=conv5_block3_2_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block3_2_bn, built=True>,\n",
       " <Activation name=conv5_block3_2_relu, built=True>,\n",
       " <Conv2D name=conv5_block3_3_conv, built=True>,\n",
       " <BatchNormalization name=conv5_block3_3_bn, built=True>,\n",
       " <Add name=conv5_block3_add, built=True>,\n",
       " <Activation name=conv5_block3_out, built=True>,\n",
       " <GlobalAveragePooling2D name=avg_pool, built=True>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m4,098\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,591,810</span> (90.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,591,810\u001b[0m (90.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> (16.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,098\u001b[0m (16.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compile our model using the **adam** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tolu/.local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 03:27:15.698115: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 321126400 exceeds 10% of free system memory.\n",
      "2025-02-16 03:27:15.964930: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 332697600 exceeds 10% of free system memory.\n",
      "2025-02-16 03:27:16.108210: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 321126400 exceeds 10% of free system memory.\n",
      "2025-02-16 03:27:16.362941: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 321126400 exceeds 10% of free system memory.\n",
      "2025-02-16 03:27:16.761071: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 321126400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 7s/step - accuracy: 0.9716 - loss: 0.0926 - val_accuracy: 0.9962 - val_loss: 0.0114\n",
      "Epoch 2/2\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 7s/step - accuracy: 0.9987 - loss: 0.0063 - val_accuracy: 0.9972 - val_loss: 0.0082\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "| 2023-01-03  | 3.0  | Artem |  Updated the file import section|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "cf2970a1d2c549fe86023eaa076d0ce4936c4275baf2cccfdad8fe6ce3a8a6c2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
